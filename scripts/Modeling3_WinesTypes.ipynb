{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lybraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "from yellowbrick.cluster.elbow import KElbowVisualizer\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from IPython.display import YouTubeVideo\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "import sompy\n",
    "from sompy.visualization.mapview import View2D\n",
    "from sompy.visualization.bmuhits import BmuHitsView\n",
    "from sompy.visualization.hitmap import HitMapView"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_clusters(df,cluster_model):\n",
    "    metrics=['silhouette','distortion','calinski_harabasz']\n",
    "    model=cluster_model\n",
    "    for score in metrics:\n",
    "        plt.figure()\n",
    "        plt.ylabel(score)\n",
    "        plt.xlabel('Number of clusters')\n",
    "        Visualizer=KElbowVisualizer(model,metric=score).fit(df)\n",
    "        plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_profiles(df, label_columns, figsize, compar_titles=None):\n",
    "    \"\"\"\n",
    "    Pass df with labels columns of one or multiple clustering labels. \n",
    "    Then specify this label columns to perform the cluster profile according to them.\n",
    "    \"\"\"\n",
    "    if compar_titles == None:\n",
    "        compar_titles = [\"\"]*len(label_columns)\n",
    "        \n",
    "    sns.set()\n",
    "    fig, axes = plt.subplots(nrows=len(label_columns), ncols=2, figsize=figsize, squeeze=False)\n",
    "    for ax, label, titl in zip(axes, label_columns, compar_titles):\n",
    "        # Filtering df\n",
    "        drop_cols = [i for i in label_columns if i!=label]\n",
    "        dfax = df.drop(drop_cols, axis=1)\n",
    "        \n",
    "        # Getting the cluster centroids and counts\n",
    "        centroids = dfax.groupby(by=label, as_index=False).mean()\n",
    "        counts = dfax.groupby(by=label, as_index=False).count().iloc[:,[0,1]]\n",
    "        counts.columns = [label, \"counts\"]\n",
    "        \n",
    "        # Setting Data\n",
    "        pd.plotting.parallel_coordinates(centroids, label, color=sns.color_palette(), ax=ax[0])\n",
    "        sns.barplot(x=label, y=\"counts\", data=counts, ax=ax[1])\n",
    "\n",
    "        #Setting Layout\n",
    "        handles, _ = ax[0].get_legend_handles_labels()\n",
    "        cluster_labels = [\"Cluster {}\".format(i) for i in range(len(handles))]\n",
    "        ax[0].annotate(text=titl, xy=(0.95,1.1), xycoords='axes fraction', fontsize=13, fontweight = 'heavy') \n",
    "        ax[0].legend(handles, cluster_labels) # Adaptable to number of clusters\n",
    "        ax[0].axhline(color=\"black\", linestyle=\"--\")\n",
    "        ax[0].set_title(\"Cluster Means - {} Clusters\".format(len(handles)), fontsize=13)\n",
    "        ax[0].set_xticklabels(ax[0].get_xticklabels(), rotation=-20)\n",
    "        ax[1].set_xticklabels(cluster_labels)\n",
    "        ax[1].set_xlabel(\"\")\n",
    "        ax[1].set_ylabel(\"Absolute Frequency\")\n",
    "        ax[1].set_title(\"Cluster Sizes - {} Clusters\".format(len(handles)), fontsize=13)\n",
    "    \n",
    "    plt.subplots_adjust(hspace=0.4, top=0.90)\n",
    "    plt.suptitle(\"Cluster Simple Profilling\", fontsize=23)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm_config(data,limit_nrcomponents):\n",
    "    bic_values =[]\n",
    "    aic_values =[]\n",
    "    types_covariance=['full','diag','spherical']\n",
    "    for i in types_covariance:\n",
    "        n_components = np.arange(1, limit_nrcomponents)\n",
    "        models = [GaussianMixture(n, covariance_type=i, n_init=10, random_state=1).fit(data)\n",
    "                  for n in n_components]\n",
    "        bic_values.append([m.bic(data) for m in models])\n",
    "        aic_values.append([m.aic(data) for m in models])\n",
    "    #barplot for BIC\n",
    "    bic=plt.figure(1)\n",
    "    X = np.arange(1,limit_nrcomponents)\n",
    "    plt.bar(X + 0.00, bic_values[0], label='full' ,color = 'b', width = 0.3)\n",
    "    plt.bar(X + 0.25, bic_values[1], label='diag',color = 'g', width = 0.3)\n",
    "    plt.bar(X + 0.50, bic_values[2], label='spherical',color = 'r', width = 0.3)\n",
    "    plt.xlabel('number of components')\n",
    "    plt.ylabel('BIC')\n",
    "    plt.legend(loc='best')\n",
    "   #barplot for AIC\n",
    "    aic=plt.figure(2)\n",
    "    X = np.arange(1,limit_nrcomponents)\n",
    "    plt.bar(X + 0.00, aic_values[0], label='full' ,color = 'b', width = 0.3)\n",
    "    plt.bar(X + 0.25, aic_values[1], label='diag',color = 'g', width = 0.3)\n",
    "    plt.bar(X + 0.50, aic_values[2], label='spherical',color = 'r', width = 0.3)\n",
    "    plt.xlabel('number of components')\n",
    "    plt.ylabel('AIC')\n",
    "    plt.legend(loc='best')\n",
    "    bic.show\n",
    "    aic.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_r2_hc(df, link_method, max_nclus, min_nclus=1, dist=\"euclidean\"):\n",
    "    \"\"\"This function computes the R2 for a set of cluster solutions given by the application of a hierarchical method.\n",
    "    The R2 is a measure of the homogenity of a cluster solution. It is based on SSt = SSw + SSb and R2 = SSb/SSt. \n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): Dataset to apply clustering\n",
    "    link_method (str): either \"ward\", \"complete\", \"average\", \"single\"\n",
    "    max_nclus (int): maximum number of clusters to compare the methods\n",
    "    min_nclus (int): minimum number of clusters to compare the methods. Defaults to 1.\n",
    "    dist (str): distance to use to compute the clustering solution. Must be a valid distance. Defaults to \"euclidean\".\n",
    "    \n",
    "    Returns:\n",
    "    ndarray: R2 values for the range of cluster solutions\n",
    "    \"\"\"\n",
    "    def get_ss(df):\n",
    "        ss = np.sum(df.var() * (df.count() - 1))\n",
    "        return ss  # return sum of sum of squares of each df variable\n",
    "    \n",
    "    sst = get_ss(df)  # get total sum of squares\n",
    "    \n",
    "    r2 = []  # where we will store the R2 metrics for each cluster solution\n",
    "    \n",
    "    for i in range(min_nclus, max_nclus+1):  # iterate over desired ncluster range\n",
    "        cluster = AgglomerativeClustering(n_clusters=i, affinity=dist, linkage=link_method)\n",
    "        hclabels = cluster.fit_predict(df) #get cluster labels\n",
    "        df_concat = pd.concat((df, pd.Series(hclabels, name='labels')), axis=1)  # concat df with labels\n",
    "        ssw_labels = df_concat.groupby(by='labels').apply(get_ss)  # compute ssw for each cluster labels\n",
    "        ssb = sst - np.sum(ssw_labels)  # remember: SST = SSW + SSB\n",
    "        r2.append(ssb / sst)  # save the R2 of the given cluster solution\n",
    "        \n",
    "    return np.array(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on 'type_covariance'-you have to insert with '', for example 'full'\n",
    "def gmm_components(data,type_covariance,min_components,max_components):\n",
    "    # Selecting number of components based on AIC and BIC\n",
    "    n_components = np.arange(min_components,max_components)\n",
    "    models = [GaussianMixture(n, covariance_type=type_covariance, n_init=10, random_state=1).fit(data)\n",
    "              for n in n_components]\n",
    "\n",
    "    bic_values = [m.bic(data) for m in models]\n",
    "    aic_values = [m.aic(data) for m in models]\n",
    "    plt.plot(n_components, bic_values, label='BIC')\n",
    "    plt.plot(n_components, aic_values, label='AIC')\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel('n_components')\n",
    "    plt.xticks(n_components)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Load the Perspective Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df = pd.read_excel('Inserirnomedoexceldapespetiva.xlsx') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perspective = normalized_df[['PERDEAL','DRYRED', 'SWEETRED','DRYWH', 'SWEETWH', 'DESSERT', 'EXOTIC']]\n",
    "perspective.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.K Means "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.K-elbow plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_clusters(perspective,KMeans( init='k-means++', n_init=15, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.Silhouette Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[SilhouetteVisualizer(KMeans(n_clusters=i,init='k-means++', n_init=15, random_state=1), colors='yellowbrick').fit(perspective).show() for i in range(2,7)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.Applying the clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'perspective' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-72bd7af97914>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#confirmar nº de k\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mkmclust\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'k-means++'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mkm_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkmclust\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperspective\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mdf_concat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperspective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkm_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'labels'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdf_concat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'labels'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'perspective' is not defined"
     ]
    }
   ],
   "source": [
    "#According to the KElbowVisualizer and the SilhouetteVisualizer we were able to determine that the optimal number of clusters is 5.\n",
    "#confirmar nº de k\n",
    "kmclust = KMeans(n_clusters=5, init='k-means++', n_init=15, random_state=1)\n",
    "km_labels = kmclust.fit_predict(perspective)\n",
    "df_concat = pd.concat((perspective, pd.Series(km_labels, name='labels')), axis=1)\n",
    "df_concat.groupby('labels').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'perspective' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-8a1bd7153064>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Making a copy of the dataset and appending a column with the cluster assigned to the observation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mkm_perspective\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mperspective\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mkm_perspective\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"km_labels\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkm_labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'perspective' is not defined"
     ]
    }
   ],
   "source": [
    "#Making a copy of the dataset and appending a column with the cluster assigned to the observation.\n",
    "km_perspective = perspective.copy()\n",
    "km_perspective[\"km_labels\"] = km_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Cluster Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_profiles(km_perspective, [\"km_labels\"],(35,10), compar_titles=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.GMM\n",
    "### 5.1.Choosing the type of covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'perspective' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-6a40ea5987ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgmm_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperspective\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'perspective' is not defined"
     ]
    }
   ],
   "source": [
    "gmm_config(perspective,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the most part, the number of components the model with the lowest AIC and BIC is 'full' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.Find the number of components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_components(perspective,'full',1,10) #escolher tipo onde esta 'full'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#According to the graph, the teams considers the optimal number of components is 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.Applying the clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing GMM clustering\n",
    "gmm = GaussianMixture(n_components=3, covariance_type='full', n_init=10, init_params='kmeans', random_state=1)\n",
    "gmm_labels = gmm.fit_predict(perspective)\n",
    "# Concatenating the labels to df\n",
    "df_concat = pd.concat([perspective, pd.Series(gmm_labels, index=perspective.index, name=\"gmm_labels\")], axis=1)\n",
    "df_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_perspective = perspective.copy()\n",
    "gmm_perspective[\"gmm_labels\"] = gmm_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.Cluster Profilling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_profiles(gmm_perspective, [\"gmm_labels\"], (35,10) , compar_titles=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.SOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.Clustering with SOMs: K-means SOM and  Hierarchical Clustering SOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This som implementation does not have a random seed parameter\n",
    "# We're going to set it up ourselves\n",
    "np.random.seed(42)\n",
    "\n",
    "# Notice that the SOM did not converge - We're under a time constraint for this class\n",
    "sm = sompy.SOMFactory().build(\n",
    "    perspective.values, \n",
    "    mapsize=(50, 50), \n",
    "    initialization='random',\n",
    "    neighborhood='gaussian',\n",
    "    training='batch',\n",
    "    lattice='hexa',\n",
    "    \n",
    ")\n",
    "sm.train(n_job=-1, verbose='info', train_rough_len=100, train_finetune_len=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinates of the units in the input space\n",
    "som_units=sm.get_node_vectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Component planes on the 50x50 grid\n",
    "sns.set()\n",
    "view2D = View2D(12,12,\"\", text_size=10)\n",
    "view2D.show(sm, col_sz=3, what='codebook')\n",
    "plt.subplots_adjust(top=0.90)\n",
    "plt.suptitle(\"Component Planes\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-matrix of the 50x50 grid\n",
    "u = sompy.umatrix.UMatrixView(12, 12, 'umatrix', show_axis=True, text_size=8, show_text=True)\n",
    "\n",
    "UMAT = u.show(\n",
    "    sm, \n",
    "    distance2=1, \n",
    "    row_normalized=False, \n",
    "    show_data=False, \n",
    "    contooor=True # Visualize isomorphic curves\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HIT-MAP\n",
    "vhts  = BmuHitsView(15,15,\"Hits Map\")\n",
    "vhts.show(sm, anotate=True, onlyzeros=False, labelsize=17, cmap=\"Blues\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.K-Means on top of SOM units\n",
    "#### 6.1.1.Number of clusters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_clusters(som_units,KMeans( init='k-means++', n_init=15, random_state=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[SilhouetteVisualizer(KMeans(n_clusters=i,init='k-means++', n_init=15, random_state=1), colors='yellowbrick').fit(som_units).show() for i in range(2,6)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.3.Apply the clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform K-Means clustering on top of the 2500 untis (sm.get_node_vectors() output)\n",
    "kmeans = KMeans(n_clusters=4, init='k-means++', n_init=20, random_state=42)\n",
    "nodeclus_labels_KM = sm.cluster(kmeans)\n",
    "\n",
    "hits  = HitMapView(12, 12,\"Clustering\", text_size=10)\n",
    "hits.show(sm, anotate=True, onlyzeros=False, labelsize=7, cmap=\"Pastel1\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perspective_nodes_KM = pd.DataFrame(som_units)\n",
    "perspective_nodes_KM['label'] = nodeclus_labels_KM\n",
    "perspective_nodes_KM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining SOM's BMUs labels\n",
    "bmus_map = sm.find_bmu(perspective)[0]  # get bmus for each observation in df\n",
    "\n",
    "perspective_bmus = pd.DataFrame(\n",
    "    np.concatenate((perspective, np.expand_dims(bmus_map,1)), axis=1),\n",
    "    index=perspective.index, columns=np.append(perspective.columns,\"BMU\")\n",
    ")\n",
    "perspective_bmus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cluster labels for each observation\n",
    "perspective_final_KMSOM =perspective_bmus.merge(perspective_nodes_KM['label'], 'left', left_on=\"BMU\", right_index=True)\n",
    "perspective_final_KMSOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Characterizing the final clusters\n",
    "perspective_final_KMSOM.drop(columns='BMU').groupby('label').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.4.Cluster Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_profiles(perspective_final_KMSOM.drop('BMU',axis=1), [\"label\"], (35,10), compar_titles=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.Hierarchical Clustering on top of SOM units\n",
    "#### 6.2.1.R2 plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input\n",
    "hc_methods = [\"ward\", \"complete\", \"average\", \"single\"]\n",
    "# Call function defined above to obtain the R2 statistic for each hc_method\n",
    "max_nclus = 10\n",
    "r2_hc_methods = np.vstack([get_r2_hc(df=pd.DataFrame(som_units), link_method=link, max_nclus=max_nclus) for link in hc_methods]).T\n",
    "r2_hc_methods = pd.DataFrame(r2_hc_methods, index=range(1, max_nclus + 1), columns=hc_methods)\n",
    "\n",
    "sns.set()\n",
    "# Plot data\n",
    "fig = plt.figure(figsize=(11,5))\n",
    "sns.lineplot(data=r2_hc_methods, linewidth=2.5, markers=[\"o\"]*4)\n",
    "\n",
    "# Finalize the plot\n",
    "fig.suptitle(\"R2 plot for various hierarchical methods\", fontsize=21)\n",
    "plt.gca().invert_xaxis()  # invert x axis\n",
    "plt.legend(title=\"HC methods\", title_fontsize=11)\n",
    "plt.xticks(range(1, max_nclus + 1))\n",
    "plt.xlabel(\"Number of clusters\", fontsize=13)\n",
    "plt.ylabel(\"R2 metric\", fontsize=13)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2.2.Dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting distance_threshold=0 and n_clusters=None ensures we compute the full tree\n",
    "linkage = 'ward'\n",
    "distance = 'euclidean'\n",
    "hclust = AgglomerativeClustering(linkage=linkage, affinity=distance, distance_threshold=0, n_clusters=None)\n",
    "hclust.fit_predict(pd.DataFrame(som_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the counts of samples under each node (number of points being merged)\n",
    "counts = np.zeros(hclust.children_.shape[0])\n",
    "n_samples = len(hclust.labels_)\n",
    "\n",
    "# hclust.children_ contains the observation ids that are being merged together\n",
    "# At the i-th iteration, children[i][0] and children[i][1] are merged to form node n_samples + i\n",
    "for i, merge in enumerate(hclust.children_):\n",
    "    # track the number of observations in the current cluster being formed\n",
    "    current_count = 0\n",
    "    for child_idx in merge:\n",
    "        if child_idx < n_samples:\n",
    "            # If this is True, then we are merging an observation\n",
    "            current_count += 1  # leaf node\n",
    "        else:\n",
    "            # Otherwise, we are merging a previously formed cluster\n",
    "            current_count += counts[child_idx - n_samples]\n",
    "    counts[i] = current_count\n",
    "\n",
    "# the hclust.children_ is used to indicate the two points/clusters being merged (dendrogram's u-joins)\n",
    "# the hclust.distances_ indicates the distance between the two points/clusters (height of the u-joins)\n",
    "# the counts indicate the number of points being merged (dendrogram's x-axis)\n",
    "linkage_matrix = np.column_stack(\n",
    "    [hclust.children_, hclust.distances_, counts]\n",
    ").astype(float)\n",
    "\n",
    "# Plot the corresponding dendrogram\n",
    "sns.set()\n",
    "fig = plt.figure(figsize=(11,5))\n",
    "# setting the threshold\n",
    "y_threshold = 30\n",
    "dendrogram(linkage_matrix, truncate_mode='level', p=5, color_threshold=y_threshold, above_threshold_color='k')\n",
    "plt.hlines(y_threshold, 0, 1000, colors=\"r\", linestyles=\"dashed\")\n",
    "plt.title(f'Hierarchical Clustering - {linkage.title()}\\'s Dendrogram', fontsize=21)\n",
    "plt.xlabel('Number of points in node (or index of point if no parenthesis)')\n",
    "plt.ylabel(f'{distance.title()} Distance', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_clusters(som_units, AgglomerativeClustering(linkage=linkage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2.4.Applying the Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Hierarchical clustering on top of the 2500 untis (sm.get_node_vectors() output)\n",
    "hierclust = AgglomerativeClustering(n_clusters=4, linkage='ward')\n",
    "nodeclus_labels_HC= sm.cluster(hierclust)\n",
    "\n",
    "hits  = HitMapView(12, 12,\"Clustering\",text_size=10)\n",
    "hits.show(sm, anotate=True, onlyzeros=False, labelsize=7, cmap=\"Pastel1\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the nodes and and respective clusters\n",
    "nodes = sm.get_node_vectors()\n",
    "\n",
    "perspective_nodes_HC = pd.DataFrame(nodes)\n",
    "perspective_nodes_HC['label'] = nodeclus_labels_HC\n",
    "perspective_nodes_HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining SOM's BMUs labels\n",
    "bmus_map = sm.find_bmu(DEMO)[0]  # get bmus for each observation in df\n",
    "\n",
    "perspective_bmus = pd.DataFrame(\n",
    "    np.concatenate((perspective, np.expand_dims(bmus_map,1)), axis=1),\n",
    "    index=perspective.index, columns=np.append(perspective.columns,\"BMU\")\n",
    ")\n",
    "perspective_bmus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cluster labels for each observation\n",
    "perspective_final_HC = DEMO_bmus.merge(DEMO_nodes_HC['label'], 'left', left_on=\"BMU\", right_index=True)\n",
    "perspective_final_HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Characterizing the final clusters\n",
    "perspective_final_HC.drop(columns='BMU').groupby('label').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2.5.Cluster Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_profiles(perspective_final_HC.drop('BMU',axis=1), [\"label\"], (35,10), compar_titles=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a csv file to afterwards import to the merging notebook.\n",
    "perspective_final_HC.to_csv('Demo(HC+SOM).csv',sep=';',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
